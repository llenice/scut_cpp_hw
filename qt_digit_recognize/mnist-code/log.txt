
1.CNN_1 without augment
Train Epoch: 0 [0/60000] Loss: 2.512203
Train Epoch: 0 [6400/60000] Loss: 1.279247
Train Epoch: 0 [12800/60000] Loss: 0.902333
Train Epoch: 0 [19200/60000] Loss: 0.534158
Train Epoch: 0 [25600/60000] Loss: 0.479809
Train Epoch: 0 [32000/60000] Loss: 0.487673
Train Epoch: 0 [38400/60000] Loss: 0.438413
Train Epoch: 0 [44800/60000] Loss: 0.287897
Train Epoch: 0 [51200/60000] Loss: 0.312215
Train Epoch: 0 [57600/60000] Loss: 0.284764

Test set: Average loss: 0.1310, Accuracy: 9701/10000 (97.01%)

Train Epoch: 1 [0/60000] Loss: 0.413248
Train Epoch: 1 [6400/60000] Loss: 0.230791
Train Epoch: 1 [12800/60000] Loss: 0.286213
Train Epoch: 1 [19200/60000] Loss: 0.261336
Train Epoch: 1 [25600/60000] Loss: 0.203010
Train Epoch: 1 [32000/60000] Loss: 0.229096
Train Epoch: 1 [38400/60000] Loss: 0.185699
Train Epoch: 1 [44800/60000] Loss: 0.211179
Train Epoch: 1 [51200/60000] Loss: 0.156261
Train Epoch: 1 [57600/60000] Loss: 0.250573

Test set: Average loss: 0.0722, Accuracy: 9821/10000 (98.21%)

Train Epoch: 2 [0/60000] Loss: 0.193794
Train Epoch: 2 [6400/60000] Loss: 0.175158
Train Epoch: 2 [12800/60000] Loss: 0.144616
Train Epoch: 2 [19200/60000] Loss: 0.130618
Train Epoch: 2 [25600/60000] Loss: 0.231569
Train Epoch: 2 [32000/60000] Loss: 0.112670
Train Epoch: 2 [38400/60000] Loss: 0.360009
Train Epoch: 2 [44800/60000] Loss: 0.073031
Train Epoch: 2 [51200/60000] Loss: 0.354403
Train Epoch: 2 [57600/60000] Loss: 0.138811

Test set: Average loss: 0.0528, Accuracy: 9862/10000 (98.62%)

Train Epoch: 3 [0/60000] Loss: 0.094937
Train Epoch: 3 [6400/60000] Loss: 0.195950
Train Epoch: 3 [12800/60000] Loss: 0.142243
Train Epoch: 3 [19200/60000] Loss: 0.139156
Train Epoch: 3 [25600/60000] Loss: 0.116641
Train Epoch: 3 [32000/60000] Loss: 0.172144
Train Epoch: 3 [38400/60000] Loss: 0.210829
Train Epoch: 3 [44800/60000] Loss: 0.126502
Train Epoch: 3 [51200/60000] Loss: 0.077247
Train Epoch: 3 [57600/60000] Loss: 0.133236

Test set: Average loss: 0.0428, Accuracy: 9885/10000 (98.85%)

Train Epoch: 4 [0/60000] Loss: 0.122641
Train Epoch: 4 [6400/60000] Loss: 0.138938
Train Epoch: 4 [12800/60000] Loss: 0.634603
Train Epoch: 4 [19200/60000] Loss: 0.076344
Train Epoch: 4 [25600/60000] Loss: 0.223974
Train Epoch: 4 [32000/60000] Loss: 0.234745
Train Epoch: 4 [38400/60000] Loss: 0.158910
Train Epoch: 4 [44800/60000] Loss: 0.150163
Train Epoch: 4 [51200/60000] Loss: 0.087333
Train Epoch: 4 [57600/60000] Loss: 0.139290

Test set: Average loss: 0.0398, Accuracy: 9897/10000 (98.97%)

Train Epoch: 5 [0/60000] Loss: 0.166719
Train Epoch: 5 [6400/60000] Loss: 0.122694
Train Epoch: 5 [12800/60000] Loss: 0.159282
Train Epoch: 5 [19200/60000] Loss: 0.131019
Train Epoch: 5 [25600/60000] Loss: 0.151638
Train Epoch: 5 [32000/60000] Loss: 0.081916
Train Epoch: 5 [38400/60000] Loss: 0.039315
Train Epoch: 5 [44800/60000] Loss: 0.099201
Train Epoch: 5 [51200/60000] Loss: 0.082309
Train Epoch: 5 [57600/60000] Loss: 0.162323

Test set: Average loss: 0.0396, Accuracy: 9892/10000 (98.92%)

Train Epoch: 6 [0/60000] Loss: 0.059726
Train Epoch: 6 [6400/60000] Loss: 0.061983
Train Epoch: 6 [12800/60000] Loss: 0.091837
Train Epoch: 6 [19200/60000] Loss: 0.055438
Train Epoch: 6 [25600/60000] Loss: 0.033007
Train Epoch: 6 [32000/60000] Loss: 0.066563
Train Epoch: 6 [38400/60000] Loss: 0.058335
Train Epoch: 6 [44800/60000] Loss: 0.136237
Train Epoch: 6 [51200/60000] Loss: 0.129684
Train Epoch: 6 [57600/60000] Loss: 0.057523

Test set: Average loss: 0.0358, Accuracy: 9898/10000 (98.98%)

Train Epoch: 7 [0/60000] Loss: 0.107830
Train Epoch: 7 [6400/60000] Loss: 0.231236
Train Epoch: 7 [12800/60000] Loss: 0.036376
Train Epoch: 7 [19200/60000] Loss: 0.123062
Train Epoch: 7 [25600/60000] Loss: 0.205131
Train Epoch: 7 [32000/60000] Loss: 0.177026
Train Epoch: 7 [38400/60000] Loss: 0.059052
Train Epoch: 7 [44800/60000] Loss: 0.226991
Train Epoch: 7 [51200/60000] Loss: 0.027121
Train Epoch: 7 [57600/60000] Loss: 0.140616

Test set: Average loss: 0.0322, Accuracy: 9902/10000 (99.02%)

Train Epoch: 8 [0/60000] Loss: 0.058500
Train Epoch: 8 [6400/60000] Loss: 0.102879
Train Epoch: 8 [12800/60000] Loss: 0.087738
Train Epoch: 8 [19200/60000] Loss: 0.142052
Train Epoch: 8 [25600/60000] Loss: 0.130754
Train Epoch: 8 [32000/60000] Loss: 0.041954
Train Epoch: 8 [38400/60000] Loss: 0.111650
Train Epoch: 8 [44800/60000] Loss: 0.195167
Train Epoch: 8 [51200/60000] Loss: 0.152020
Train Epoch: 8 [57600/60000] Loss: 0.320804

Test set: Average loss: 0.0320, Accuracy: 9910/10000 (99.10%)

Train Epoch: 9 [0/60000] Loss: 0.075768
Train Epoch: 9 [6400/60000] Loss: 0.151433
Train Epoch: 9 [12800/60000] Loss: 0.076093
Train Epoch: 9 [19200/60000] Loss: 0.206684
Train Epoch: 9 [25600/60000] Loss: 0.086430
Train Epoch: 9 [32000/60000] Loss: 0.138347
Train Epoch: 9 [38400/60000] Loss: 0.063491
Train Epoch: 9 [44800/60000] Loss: 0.078674
Train Epoch: 9 [51200/60000] Loss: 0.123047
Train Epoch: 9 [57600/60000] Loss: 0.091824

Test set: Average loss: 0.0322, Accuracy: 9905/10000 (99.05%)

Train Epoch: 10 [0/60000] Loss: 0.246435
Train Epoch: 10 [6400/60000] Loss: 0.057756
Train Epoch: 10 [12800/60000] Loss: 0.145805
Train Epoch: 10 [19200/60000] Loss: 0.100237
Train Epoch: 10 [25600/60000] Loss: 0.070842
Train Epoch: 10 [32000/60000] Loss: 0.145083
Train Epoch: 10 [38400/60000] Loss: 0.046681
Train Epoch: 10 [44800/60000] Loss: 0.107314
Train Epoch: 10 [51200/60000] Loss: 0.093336
Train Epoch: 10 [57600/60000] Loss: 0.067623

Test set: Average loss: 0.0315, Accuracy: 9908/10000 (99.08%)

Train Epoch: 11 [0/60000] Loss: 0.122859
Train Epoch: 11 [6400/60000] Loss: 0.180939
Train Epoch: 11 [12800/60000] Loss: 0.028076
Train Epoch: 11 [19200/60000] Loss: 0.081886
Train Epoch: 11 [25600/60000] Loss: 0.202489
Train Epoch: 11 [32000/60000] Loss: 0.047270
Train Epoch: 11 [38400/60000] Loss: 0.111586
Train Epoch: 11 [44800/60000] Loss: 0.084051
Train Epoch: 11 [51200/60000] Loss: 0.081423
Train Epoch: 11 [57600/60000] Loss: 0.099075

Test set: Average loss: 0.0300, Accuracy: 9912/10000 (99.12%)

Train Epoch: 12 [0/60000] Loss: 0.155381
Train Epoch: 12 [6400/60000] Loss: 0.233201
Train Epoch: 12 [12800/60000] Loss: 0.056750
Train Epoch: 12 [19200/60000] Loss: 0.058167
Train Epoch: 12 [25600/60000] Loss: 0.060347
Train Epoch: 12 [32000/60000] Loss: 0.211677
Train Epoch: 12 [38400/60000] Loss: 0.247058
Train Epoch: 12 [44800/60000] Loss: 0.060069
Train Epoch: 12 [51200/60000] Loss: 0.036803
Train Epoch: 12 [57600/60000] Loss: 0.162533

Test set: Average loss: 0.0304, Accuracy: 9915/10000 (99.15%)

Train Epoch: 13 [0/60000] Loss: 0.150185
Train Epoch: 13 [6400/60000] Loss: 0.062010
Train Epoch: 13 [12800/60000] Loss: 0.046138
Train Epoch: 13 [19200/60000] Loss: 0.081535
Train Epoch: 13 [25600/60000] Loss: 0.079286
Train Epoch: 13 [32000/60000] Loss: 0.127330
Train Epoch: 13 [38400/60000] Loss: 0.046137
Train Epoch: 13 [44800/60000] Loss: 0.062129
Train Epoch: 13 [51200/60000] Loss: 0.124390
Train Epoch: 13 [57600/60000] Loss: 0.149247

Test set: Average loss: 0.0301, Accuracy: 9915/10000 (99.15%)

Train Epoch: 14 [0/60000] Loss: 0.032991
Train Epoch: 14 [6400/60000] Loss: 0.108032
Train Epoch: 14 [12800/60000] Loss: 0.055842
Train Epoch: 14 [19200/60000] Loss: 0.095328
Train Epoch: 14 [25600/60000] Loss: 0.058097
Train Epoch: 14 [32000/60000] Loss: 0.018221
Train Epoch: 14 [38400/60000] Loss: 0.052528
Train Epoch: 14 [44800/60000] Loss: 0.094920
Train Epoch: 14 [51200/60000] Loss: 0.133609
Train Epoch: 14 [57600/60000] Loss: 0.120259

Test set: Average loss: 0.0298, Accuracy: 9917/10000 (99.17%)



2.CNN  1 with augment
开始训练 15 个周期，使用设备: cuda...
训练数据增强流程: Compose(
    RandomAffine(degrees=[-10.0, 10.0], translate=(0.1, 0.1))
    ToTensor()
    AddGaussianNoise(mean=0.0, std=0.1)
    Normalize(mean=(0.1307,), std=(0.3081,))
)
训练周期: 1 [0/60000 (0%)]      损失: 2.504930
训练周期: 1 [6400/60000 (11%)]  损失: 1.480888
训练周期: 1 [12800/60000 (21%)] 损失: 0.959613
训练周期: 1 [19200/60000 (32%)] 损失: 0.601787
训练周期: 1 [25600/60000 (43%)] 损失: 0.525075
训练周期: 1 [32000/60000 (53%)] 损失: 0.565876
训练周期: 1 [38400/60000 (64%)] 损失: 0.503648
训练周期: 1 [44800/60000 (75%)] 损失: 0.417118
训练周期: 1 [51200/60000 (85%)] 损失: 0.358029
训练周期: 1 [57600/60000 (96%)] 损失: 0.462065

测试集 (周期 1): 平均损失: 0.1223, 准确率: 9712/10000 (97.12%)

训练周期: 2 [0/60000 (0%)]      损失: 0.406614
训练周期: 2 [6400/60000 (11%)]  损失: 0.279842
训练周期: 2 [12800/60000 (21%)] 损失: 0.258471
训练周期: 2 [19200/60000 (32%)] 损失: 0.280848
训练周期: 2 [25600/60000 (43%)] 损失: 0.224805
训练周期: 2 [32000/60000 (53%)] 损失: 0.264870
训练周期: 2 [38400/60000 (64%)] 损失: 0.196956
训练周期: 2 [44800/60000 (75%)] 损失: 0.185008
训练周期: 2 [51200/60000 (85%)] 损失: 0.405619
训练周期: 2 [57600/60000 (96%)] 损失: 0.311855

测试集 (周期 2): 平均损失: 0.0661, 准确率: 9822/10000 (98.22%)

训练周期: 3 [0/60000 (0%)]      损失: 0.229999
训练周期: 3 [6400/60000 (11%)]  损失: 0.154648
训练周期: 3 [12800/60000 (21%)] 损失: 0.174260
训练周期: 3 [19200/60000 (32%)] 损失: 0.122580
训练周期: 3 [25600/60000 (43%)] 损失: 0.238021
训练周期: 3 [32000/60000 (53%)] 损失: 0.222361
训练周期: 3 [38400/60000 (64%)] 损失: 0.168181
训练周期: 3 [44800/60000 (75%)] 损失: 0.231571
训练周期: 3 [51200/60000 (85%)] 损失: 0.287442
训练周期: 3 [57600/60000 (96%)] 损失: 0.280545

测试集 (周期 3): 平均损失: 0.0529, 准确率: 9861/10000 (98.61%)

训练周期: 4 [0/60000 (0%)]      损失: 0.336700
训练周期: 4 [6400/60000 (11%)]  损失: 0.148650
训练周期: 4 [12800/60000 (21%)] 损失: 0.384460
训练周期: 4 [19200/60000 (32%)] 损失: 0.120885
训练周期: 4 [25600/60000 (43%)] 损失: 0.127294
训练周期: 4 [32000/60000 (53%)] 损失: 0.110877
训练周期: 4 [38400/60000 (64%)] 损失: 0.095245
训练周期: 4 [44800/60000 (75%)] 损失: 0.206596
训练周期: 4 [51200/60000 (85%)] 损失: 0.090659
训练周期: 4 [57600/60000 (96%)] 损失: 0.087053

测试集 (周期 4): 平均损失: 0.0497, 准确率: 9864/10000 (98.64%)

训练周期: 5 [0/60000 (0%)]      损失: 0.167922
训练周期: 5 [6400/60000 (11%)]  损失: 0.257638
训练周期: 5 [12800/60000 (21%)] 损失: 0.218269
训练周期: 5 [19200/60000 (32%)] 损失: 0.087545
训练周期: 5 [25600/60000 (43%)] 损失: 0.102793
训练周期: 5 [32000/60000 (53%)] 损失: 0.049906
训练周期: 5 [38400/60000 (64%)] 损失: 0.066921
训练周期: 5 [44800/60000 (75%)] 损失: 0.130062
训练周期: 5 [51200/60000 (85%)] 损失: 0.125579
训练周期: 5 [57600/60000 (96%)] 损失: 0.143452

测试集 (周期 5): 平均损失: 0.0401, 准确率: 9892/10000 (98.92%)

训练周期: 6 [0/60000 (0%)]      损失: 0.112883
训练周期: 6 [6400/60000 (11%)]  损失: 0.137971
训练周期: 6 [12800/60000 (21%)] 损失: 0.163336
训练周期: 6 [19200/60000 (32%)] 损失: 0.158353
训练周期: 6 [25600/60000 (43%)] 损失: 0.192137
训练周期: 6 [32000/60000 (53%)] 损失: 0.070623
训练周期: 6 [38400/60000 (64%)] 损失: 0.044719
训练周期: 6 [44800/60000 (75%)] 损失: 0.235594
训练周期: 6 [51200/60000 (85%)] 损失: 0.123205
训练周期: 6 [57600/60000 (96%)] 损失: 0.069063

测试集 (周期 6): 平均损失: 0.0357, 准确率: 9897/10000 (98.97%)

训练周期: 7 [0/60000 (0%)]      损失: 0.134755
训练周期: 7 [6400/60000 (11%)]  损失: 0.125283
训练周期: 7 [12800/60000 (21%)] 损失: 0.047039
训练周期: 7 [19200/60000 (32%)] 损失: 0.057488
训练周期: 7 [25600/60000 (43%)] 损失: 0.147625
训练周期: 7 [32000/60000 (53%)] 损失: 0.116359
训练周期: 7 [38400/60000 (64%)] 损失: 0.124736
训练周期: 7 [44800/60000 (75%)] 损失: 0.086282
训练周期: 7 [51200/60000 (85%)] 损失: 0.132348
训练周期: 7 [57600/60000 (96%)] 损失: 0.152184

测试集 (周期 7): 平均损失: 0.0372, 准确率: 9885/10000 (98.85%)

训练周期: 8 [0/60000 (0%)]      损失: 0.065847
训练周期: 8 [6400/60000 (11%)]  损失: 0.061274
训练周期: 8 [12800/60000 (21%)] 损失: 0.283031
训练周期: 8 [19200/60000 (32%)] 损失: 0.107271
训练周期: 8 [25600/60000 (43%)] 损失: 0.101734
训练周期: 8 [32000/60000 (53%)] 损失: 0.107513
训练周期: 8 [38400/60000 (64%)] 损失: 0.089295
训练周期: 8 [44800/60000 (75%)] 损失: 0.153943
训练周期: 8 [51200/60000 (85%)] 损失: 0.121497
训练周期: 8 [57600/60000 (96%)] 损失: 0.235057

测试集 (周期 8): 平均损失: 0.0344, 准确率: 9889/10000 (98.89%)

训练周期: 9 [0/60000 (0%)]      损失: 0.163081
训练周期: 9 [6400/60000 (11%)]  损失: 0.262602
训练周期: 9 [12800/60000 (21%)] 损失: 0.132734
训练周期: 9 [19200/60000 (32%)] 损失: 0.098565
训练周期: 9 [25600/60000 (43%)] 损失: 0.093972
训练周期: 9 [32000/60000 (53%)] 损失: 0.106086
训练周期: 9 [38400/60000 (64%)] 损失: 0.194784
训练周期: 9 [44800/60000 (75%)] 损失: 0.184673
训练周期: 9 [51200/60000 (85%)] 损失: 0.082604
训练周期: 9 [57600/60000 (96%)] 损失: 0.202158

测试集 (周期 9): 平均损失: 0.0342, 准确率: 9892/10000 (98.92%)

训练周期: 10 [0/60000 (0%)]     损失: 0.082301
训练周期: 10 [6400/60000 (11%)] 损失: 0.123543
训练周期: 10 [12800/60000 (21%)]        损失: 0.036208
训练周期: 10 [19200/60000 (32%)]        损失: 0.208785
训练周期: 10 [25600/60000 (43%)]        损失: 0.081650
训练周期: 10 [32000/60000 (53%)]        损失: 0.148747
训练周期: 10 [38400/60000 (64%)]        损失: 0.128419
训练周期: 10 [44800/60000 (75%)]        损失: 0.107356
训练周期: 10 [51200/60000 (85%)]        损失: 0.086277
训练周期: 10 [57600/60000 (96%)]        损失: 0.140530

测试集 (周期 10): 平均损失: 0.0338, 准确率: 9896/10000 (98.96%)

训练周期: 11 [0/60000 (0%)]     损失: 0.150358
训练周期: 11 [6400/60000 (11%)] 损失: 0.160230
训练周期: 11 [12800/60000 (21%)]        损失: 0.148527
训练周期: 11 [19200/60000 (32%)]        损失: 0.080748
训练周期: 11 [25600/60000 (43%)]        损失: 0.124583
训练周期: 11 [32000/60000 (53%)]        损失: 0.132215
训练周期: 11 [38400/60000 (64%)]        损失: 0.087215
训练周期: 11 [44800/60000 (75%)]        损失: 0.147802
训练周期: 11 [51200/60000 (85%)]        损失: 0.022855
训练周期: 11 [57600/60000 (96%)]        损失: 0.069398

测试集 (周期 11): 平均损失: 0.0331, 准确率: 9898/10000 (98.98%)

训练周期: 12 [0/60000 (0%)]     损失: 0.053684
训练周期: 12 [6400/60000 (11%)] 损失: 0.082152
训练周期: 12 [12800/60000 (21%)]        损失: 0.109884
训练周期: 12 [19200/60000 (32%)]        损失: 0.035173
训练周期: 12 [25600/60000 (43%)]        损失: 0.096027
训练周期: 12 [32000/60000 (53%)]        损失: 0.111725
训练周期: 12 [38400/60000 (64%)]        损失: 0.055232
训练周期: 12 [44800/60000 (75%)]        损失: 0.203536
训练周期: 12 [51200/60000 (85%)]        损失: 0.081254
训练周期: 12 [57600/60000 (96%)]        损失: 0.106163

测试集 (周期 12): 平均损失: 0.0329, 准确率: 9902/10000 (99.02%)

训练周期: 13 [0/60000 (0%)]     损失: 0.160528
训练周期: 13 [6400/60000 (11%)] 损失: 0.119707
训练周期: 13 [12800/60000 (21%)]        损失: 0.092765
训练周期: 13 [19200/60000 (32%)]        损失: 0.050277
训练周期: 13 [25600/60000 (43%)]        损失: 0.104825
训练周期: 13 [32000/60000 (53%)]        损失: 0.159673
训练周期: 13 [38400/60000 (64%)]        损失: 0.166989
训练周期: 13 [44800/60000 (75%)]        损失: 0.183003
训练周期: 13 [51200/60000 (85%)]        损失: 0.030698
训练周期: 13 [57600/60000 (96%)]        损失: 0.109653

测试集 (周期 13): 平均损失: 0.0329, 准确率: 9898/10000 (98.98%)

训练周期: 14 [0/60000 (0%)]     损失: 0.143332
训练周期: 14 [6400/60000 (11%)] 损失: 0.078333
训练周期: 14 [12800/60000 (21%)]        损失: 0.099745
训练周期: 14 [19200/60000 (32%)]        损失: 0.098178
训练周期: 14 [25600/60000 (43%)]        损失: 0.081027
训练周期: 14 [32000/60000 (53%)]        损失: 0.125997
训练周期: 14 [38400/60000 (64%)]        损失: 0.125777
训练周期: 14 [44800/60000 (75%)]        损失: 0.087029
训练周期: 14 [51200/60000 (85%)]        损失: 0.055292
训练周期: 14 [57600/60000 (96%)]        损失: 0.198743

测试集 (周期 14): 平均损失: 0.0324, 准确率: 9899/10000 (98.99%)

训练周期: 15 [0/60000 (0%)]     损失: 0.057210
训练周期: 15 [6400/60000 (11%)] 损失: 0.097045
训练周期: 15 [12800/60000 (21%)]        损失: 0.093096
训练周期: 15 [19200/60000 (32%)]        损失: 0.190594
训练周期: 15 [25600/60000 (43%)]        损失: 0.151181
训练周期: 15 [32000/60000 (53%)]        损失: 0.053873
训练周期: 15 [38400/60000 (64%)]        损失: 0.059330
训练周期: 15 [44800/60000 (75%)]        损失: 0.076887
训练周期: 15 [51200/60000 (85%)]        损失: 0.278556
训练周期: 15 [57600/60000 (96%)]        损失: 0.056657

测试集 (周期 15): 平均损失: 0.0328, 准确率: 9898/10000 (98.98%)

训练完成，模型已保存至 mnist_augmented_cnn.pth


3.resnet lite
开始使用定制版 ResNet 在设备 'cuda' 上训练 10 个周期...
周期 [1/10], 步骤 [100/469], 损失: 0.1410
周期 [1/10], 步骤 [200/469], 损失: 0.0962
周期 [1/10], 步骤 [300/469], 损失: 0.0748
周期 [1/10], 步骤 [400/469], 损失: 0.1726
--- 周期 1 结束 ---
测试集准确率: 98.26 %
-------------------------
周期 [2/10], 步骤 [100/469], 损失: 0.0661
周期 [2/10], 步骤 [200/469], 损失: 0.0691
周期 [2/10], 步骤 [300/469], 损失: 0.0319
周期 [2/10], 步骤 [400/469], 损失: 0.0568
--- 周期 2 结束 ---
测试集准确率: 99.15 %
-------------------------
周期 [3/10], 步骤 [100/469], 损失: 0.0548
周期 [3/10], 步骤 [200/469], 损失: 0.0225
周期 [3/10], 步骤 [300/469], 损失: 0.0123
周期 [3/10], 步骤 [400/469], 损失: 0.0225
--- 周期 3 结束 ---
测试集准确率: 99.14 %
-------------------------
周期 [4/10], 步骤 [100/469], 损失: 0.0373
周期 [4/10], 步骤 [200/469], 损失: 0.0492
周期 [4/10], 步骤 [300/469], 损失: 0.0192
周期 [4/10], 步骤 [400/469], 损失: 0.0120
--- 周期 4 结束 ---
测试集准确率: 99.48 %
-------------------------
周期 [5/10], 步骤 [100/469], 损失: 0.0095
周期 [5/10], 步骤 [200/469], 损失: 0.0185
周期 [5/10], 步骤 [300/469], 损失: 0.0202
周期 [5/10], 步骤 [400/469], 损失: 0.0453
--- 周期 5 结束 ---
测试集准确率: 99.41 %
-------------------------
周期 [6/10], 步骤 [100/469], 损失: 0.0056
周期 [6/10], 步骤 [200/469], 损失: 0.0310
周期 [6/10], 步骤 [300/469], 损失: 0.0148
周期 [6/10], 步骤 [400/469], 损失: 0.0077
--- 周期 6 结束 ---
测试集准确率: 99.33 %
-------------------------
周期 [7/10], 步骤 [100/469], 损失: 0.0344
周期 [7/10], 步骤 [200/469], 损失: 0.0217
周期 [7/10], 步骤 [300/469], 损失: 0.0039
周期 [7/10], 步骤 [400/469], 损失: 0.0071
--- 周期 7 结束 ---
测试集准确率: 99.58 %
-------------------------
周期 [8/10], 步骤 [100/469], 损失: 0.0104
周期 [8/10], 步骤 [200/469], 损失: 0.0036
周期 [8/10], 步骤 [300/469], 损失: 0.0018
周期 [8/10], 步骤 [400/469], 损失: 0.0103
--- 周期 8 结束 ---
测试集准确率: 99.56 %
-------------------------
周期 [9/10], 步骤 [100/469], 损失: 0.0074
周期 [9/10], 步骤 [200/469], 损失: 0.0171
周期 [9/10], 步骤 [300/469], 损失: 0.0293
周期 [9/10], 步骤 [400/469], 损失: 0.0051
--- 周期 9 结束 ---
测试集准确率: 99.64 %
-------------------------
周期 [10/10], 步骤 [100/469], 损失: 0.0185
周期 [10/10], 步骤 [200/469], 损失: 0.0032
周期 [10/10], 步骤 [300/469], 损失: 0.0045
周期 [10/10], 步骤 [400/469], 损失: 0.0030
--- 周期 10 结束 ---
测试集准确率: 99.64 %
-------------------------
训练完成，模型已保存至 'mnist_resnet_model.pth'


4.ViT
开始使用 ViT 在【标准MNIST】上训练 10 个周期...
周期 1/10 | 测试集准确率: 95.62%
周期 2/10 | 测试集准确率: 96.28%
周期 3/10 | 测试集准确率: 97.15%
周期 4/10 | 测试集准确率: 97.69%
周期 5/10 | 测试集准确率: 98.19%
周期 6/10 | 测试集准确率: 98.19%
周期 7/10 | 测试集准确率: 97.81%
周期 8/10 | 测试集准确率: 98.37%
周期 9/10 | 测试集准确率: 98.06%
周期 10/10 | 测试集准确率: 98.75%

训练完成，模型已保存至 'mnist_vit_model.pth'